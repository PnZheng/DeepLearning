{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/PnZheng/DeepLearning/blob/main/GAN/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2Pix\n",
    " \n",
    "### 鞋子的数据集下载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:19.905652Z",
     "start_time": "2021-04-25T06:22:19.902171Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "gGGJCgylfwEy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('ShoeV2_photo'):\n",
    "    !wget https://www.dropbox.com/s/g6b6gtvmdu0h77x/ShoeV2_photo.zip\n",
    "    !unzip -q ShoeV2_photo.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些必要包的加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:25.707794Z",
     "start_time": "2021-04-25T06:22:19.908378Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "6AC0roPnfwE4",
    "outputId": "3bfe139e-bcb7-4ac9-f521-b064a95dc2ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 23:45:03.436 | WARNING  | torch_snippets:<module>:13 - sklearn is not found. Skipping relevant imports from submodule `sklegos`\n",
      "Exception: No module named 'sklego'\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch_snippets\n",
    "from torch_snippets import *\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义图像的边缘检测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:25.718312Z",
     "start_time": "2021-04-25T06:22:25.709314Z"
    },
    "id": "VwH3HJj-fwE7"
   },
   "outputs": [],
   "source": [
    "def detect_edges(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_gray = cv2.bilateralFilter(img_gray, 5, 50, 50)\n",
    "    img_gray_edges = cv2.Canny(img_gray, 45, 100)\n",
    "    img_gray_edges = cv2.bitwise_not(img_gray_edges) # invert black/white\n",
    "    img_edges = cv2.cvtColor(img_gray_edges, cv2.COLOR_GRAY2RGB)\n",
    "    return img_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义图像的转换管道（预处理和标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "\n",
    "preprocess = T.Compose([\n",
    "    T.Lambda(lambda x: torch.Tensor(x.copy()).permute(2, 0, 1).to(device))\n",
    "])\n",
    "\n",
    "normalize = lambda x: (x - 127.5)/127.5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义数据集的类\n",
    "- 在这个类中会鞋进行的边缘图像提取（下图中的第二张图），并在图上不同部分洒上所需要的颜色，如下图中的第三张图，并与第一张图进行绑定。\n",
    "- 在getitem中，先对图像抓取边缘，对此进行调整大小和标准化。然后随机将原始图像的颜色“撒”上去后，进行预处理。\n",
    "![Imgur](https://i.imgur.com/ZYfoum2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShoesData(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, ix):\n",
    "        f = self.items[ix]\n",
    "        try: im = read(f, 1)\n",
    "        except:\n",
    "            blank = preprocess(Blank(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "            return blank, blank\n",
    "        edges = detect_edges(im)\n",
    "        im, edges = resize(im, IMAGE_SIZE), resize(edges, IMAGE_SIZE)\n",
    "        im, edges = normalize(im), normalize(edges)\n",
    "        self._draw_color_circles_on_src_img(edges, im)\n",
    "        im, edges = preprocess(im), preprocess(edges)\n",
    "        return edges, im\n",
    "\n",
    "    def _draw_color_circles_on_src_img(self, img_src, img_target):\n",
    "        non_white_coords = self._get_non_white_coordinates(img_target)\n",
    "        for center_y, center_x in non_white_coords:\n",
    "            self._draw_color_circle_on_src_img(img_src, img_target, center_y, center_x)\n",
    "\n",
    "    def _get_non_white_coordinates(self, img):\n",
    "        non_white_mask = np.sum(img, axis=-1) < 2.75\n",
    "        non_white_y, non_white_x = np.nonzero(non_white_mask)\n",
    "        # 随机采样非白色坐标\n",
    "        n_non_white = len(non_white_y)\n",
    "        n_color_points = min(n_non_white, 300)\n",
    "        idxs = np.random.choice(n_non_white, n_color_points, replace=False)\n",
    "        non_white_coords = list(zip(non_white_y[idxs], non_white_x[idxs]))\n",
    "        return non_white_coords\n",
    "\n",
    "    def _draw_color_circle_on_src_img(self, img_src, img_target, center_y, center_x):\n",
    "        assert img_src.shape == img_target.shape, \"Image source and target must have same shape.\"\n",
    "        y0, y1, x0, x1 = self._get_color_point_bbox_coords(center_y, center_x)\n",
    "        color = np.mean(img_target[y0:y1, x0:x1], axis=(0, 1))\n",
    "        img_src[y0:y1, x0:x1] = color\n",
    "\n",
    "    def _get_color_point_bbox_coords(self, center_y, center_x):\n",
    "        radius = 2\n",
    "        y0 = max(0, center_y-radius+1)\n",
    "        y1 = min(IMAGE_SIZE, center_y+radius)\n",
    "        x0 = max(0, center_x-radius+1)\n",
    "        x1 = min(IMAGE_SIZE, center_x+radius)\n",
    "        return y0, y1, x0, x1\n",
    "\n",
    "    def choose(self): return self[randint(len(self))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义数据集的datasets和dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:28.203506Z",
     "start_time": "2021-04-25T06:22:25.720118Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "iI_eZIO_fwE-",
    "outputId": "264378f1-4568-4996-a13e-92ec282fbce9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-06 12:58:35.075 | INFO     | torch_snippets.paths:inner:24 - 4381 files found at ShoeV2_photo/*.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "Tensor\tShape: torch.Size([32, 3, 256, 256])\tMin: -1.000\tMax: 1.000\tMean: 0.876\tdtype: torch.float32\n",
      "==================================================================\n",
      "Tensor\tShape: torch.Size([32, 3, 256, 256])\tMin: -1.000\tMax: 1.000\tMean: 0.583\tdtype: torch.float32\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_items, val_items = train_test_split(Glob('ShoeV2_photo/*.png'), test_size=0.2, random_state=2)\n",
    "trn_ds, val_ds = ShoesData(train_items), ShoesData(val_items)\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "inspect(*next(iter(trn_dl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义生成器和判别器、权重初始化函数\n",
    "\n",
    "这里先定义了UNetDown和UNetUp结构，随后再利用这两部分来定义GeneratorUNet和Discriminator结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:28.222005Z",
     "start_time": "2021-04-25T06:22:28.204697Z"
    },
    "id": "rot3Fn3ufwFA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e3c9418b51b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mUNetDown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUNetDown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128)\n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "        return self.final(u7)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例化是生成器和判别器，并用summary打印网络结构和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:30.823685Z",
     "start_time": "2021-04-25T06:22:28.223083Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtSqQ1U-fwFD",
    "outputId": "3f59c1bd-b184-47dc-bba4-6b051eb75a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─UNetDown: 1-1                          [-1, 64, 128, 128]        --\n",
      "|    └─Sequential: 2-1                   [-1, 64, 128, 128]        --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 128, 128]        3,072\n",
      "|    |    └─LeakyReLU: 3-2               [-1, 64, 128, 128]        --\n",
      "├─UNetDown: 1-2                          [-1, 128, 64, 64]         --\n",
      "|    └─Sequential: 2-2                   [-1, 128, 64, 64]         --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 128, 64, 64]         131,072\n",
      "|    |    └─InstanceNorm2d: 3-4          [-1, 128, 64, 64]         --\n",
      "|    |    └─LeakyReLU: 3-5               [-1, 128, 64, 64]         --\n",
      "├─UNetDown: 1-3                          [-1, 256, 32, 32]         --\n",
      "|    └─Sequential: 2-3                   [-1, 256, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-6                  [-1, 256, 32, 32]         524,288\n",
      "|    |    └─InstanceNorm2d: 3-7          [-1, 256, 32, 32]         --\n",
      "|    |    └─LeakyReLU: 3-8               [-1, 256, 32, 32]         --\n",
      "├─UNetDown: 1-4                          [-1, 512, 16, 16]         --\n",
      "|    └─Sequential: 2-4                   [-1, 512, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 512, 16, 16]         2,097,152\n",
      "|    |    └─InstanceNorm2d: 3-10         [-1, 512, 16, 16]         --\n",
      "|    |    └─LeakyReLU: 3-11              [-1, 512, 16, 16]         --\n",
      "|    |    └─Dropout: 3-12                [-1, 512, 16, 16]         --\n",
      "├─UNetDown: 1-5                          [-1, 512, 8, 8]           --\n",
      "|    └─Sequential: 2-5                   [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 512, 8, 8]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-14         [-1, 512, 8, 8]           --\n",
      "|    |    └─LeakyReLU: 3-15              [-1, 512, 8, 8]           --\n",
      "|    |    └─Dropout: 3-16                [-1, 512, 8, 8]           --\n",
      "├─UNetDown: 1-6                          [-1, 512, 4, 4]           --\n",
      "|    └─Sequential: 2-6                   [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 512, 4, 4]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-18         [-1, 512, 4, 4]           --\n",
      "|    |    └─LeakyReLU: 3-19              [-1, 512, 4, 4]           --\n",
      "|    |    └─Dropout: 3-20                [-1, 512, 4, 4]           --\n",
      "├─UNetDown: 1-7                          [-1, 512, 2, 2]           --\n",
      "|    └─Sequential: 2-7                   [-1, 512, 2, 2]           --\n",
      "|    |    └─Conv2d: 3-21                 [-1, 512, 2, 2]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-22         [-1, 512, 2, 2]           --\n",
      "|    |    └─LeakyReLU: 3-23              [-1, 512, 2, 2]           --\n",
      "|    |    └─Dropout: 3-24                [-1, 512, 2, 2]           --\n",
      "├─UNetDown: 1-8                          [-1, 512, 1, 1]           --\n",
      "|    └─Sequential: 2-8                   [-1, 512, 1, 1]           --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 512, 1, 1]           4,194,304\n",
      "|    |    └─LeakyReLU: 3-26              [-1, 512, 1, 1]           --\n",
      "|    |    └─Dropout: 3-27                [-1, 512, 1, 1]           --\n",
      "├─UNetUp: 1-9                            [-1, 1024, 2, 2]          --\n",
      "|    └─Sequential: 2-9                   [-1, 512, 2, 2]           --\n",
      "|    |    └─ConvTranspose2d: 3-28        [-1, 512, 2, 2]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-29         [-1, 512, 2, 2]           --\n",
      "|    |    └─ReLU: 3-30                   [-1, 512, 2, 2]           --\n",
      "|    |    └─Dropout: 3-31                [-1, 512, 2, 2]           --\n",
      "├─UNetUp: 1-10                           [-1, 1024, 4, 4]          --\n",
      "|    └─Sequential: 2-10                  [-1, 512, 4, 4]           --\n",
      "|    |    └─ConvTranspose2d: 3-32        [-1, 512, 4, 4]           8,388,608\n",
      "|    |    └─InstanceNorm2d: 3-33         [-1, 512, 4, 4]           --\n",
      "|    |    └─ReLU: 3-34                   [-1, 512, 4, 4]           --\n",
      "|    |    └─Dropout: 3-35                [-1, 512, 4, 4]           --\n",
      "├─UNetUp: 1-11                           [-1, 1024, 8, 8]          --\n",
      "|    └─Sequential: 2-11                  [-1, 512, 8, 8]           --\n",
      "|    |    └─ConvTranspose2d: 3-36        [-1, 512, 8, 8]           8,388,608\n",
      "|    |    └─InstanceNorm2d: 3-37         [-1, 512, 8, 8]           --\n",
      "|    |    └─ReLU: 3-38                   [-1, 512, 8, 8]           --\n",
      "|    |    └─Dropout: 3-39                [-1, 512, 8, 8]           --\n",
      "├─UNetUp: 1-12                           [-1, 1024, 16, 16]        --\n",
      "|    └─Sequential: 2-12                  [-1, 512, 16, 16]         --\n",
      "|    |    └─ConvTranspose2d: 3-40        [-1, 512, 16, 16]         8,388,608\n",
      "|    |    └─InstanceNorm2d: 3-41         [-1, 512, 16, 16]         --\n",
      "|    |    └─ReLU: 3-42                   [-1, 512, 16, 16]         --\n",
      "|    |    └─Dropout: 3-43                [-1, 512, 16, 16]         --\n",
      "├─UNetUp: 1-13                           [-1, 512, 32, 32]         --\n",
      "|    └─Sequential: 2-13                  [-1, 256, 32, 32]         --\n",
      "|    |    └─ConvTranspose2d: 3-44        [-1, 256, 32, 32]         4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-45         [-1, 256, 32, 32]         --\n",
      "|    |    └─ReLU: 3-46                   [-1, 256, 32, 32]         --\n",
      "├─UNetUp: 1-14                           [-1, 256, 64, 64]         --\n",
      "|    └─Sequential: 2-14                  [-1, 128, 64, 64]         --\n",
      "|    |    └─ConvTranspose2d: 3-47        [-1, 128, 64, 64]         1,048,576\n",
      "|    |    └─InstanceNorm2d: 3-48         [-1, 128, 64, 64]         --\n",
      "|    |    └─ReLU: 3-49                   [-1, 128, 64, 64]         --\n",
      "├─UNetUp: 1-15                           [-1, 128, 128, 128]       --\n",
      "|    └─Sequential: 2-15                  [-1, 64, 128, 128]        --\n",
      "|    |    └─ConvTranspose2d: 3-50        [-1, 64, 128, 128]        262,144\n",
      "|    |    └─InstanceNorm2d: 3-51         [-1, 64, 128, 128]        --\n",
      "|    |    └─ReLU: 3-52                   [-1, 64, 128, 128]        --\n",
      "├─Sequential: 1-16                       [-1, 3, 256, 256]         --\n",
      "|    └─Upsample: 2-16                    [-1, 128, 256, 256]       --\n",
      "|    └─ZeroPad2d: 2-17                   [-1, 128, 257, 257]       --\n",
      "|    └─Conv2d: 2-18                      [-1, 3, 256, 256]         6,147\n",
      "|    └─Tanh: 2-19                        [-1, 3, 256, 256]         --\n",
      "==========================================================================================\n",
      "Total params: 54,404,099\n",
      "Trainable params: 54,404,099\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 18.25\n",
      "==========================================================================================\n",
      "Input size (MB): 2.25\n",
      "Forward/backward pass size (MB): 32.16\n",
      "Params size (MB): 207.54\n",
      "Estimated Total Size (MB): 241.95\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─UNetDown: 1-1                          [-1, 64, 128, 128]        --\n",
      "|    └─Sequential: 2-1                   [-1, 64, 128, 128]        --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 128, 128]        3,072\n",
      "|    |    └─LeakyReLU: 3-2               [-1, 64, 128, 128]        --\n",
      "├─UNetDown: 1-2                          [-1, 128, 64, 64]         --\n",
      "|    └─Sequential: 2-2                   [-1, 128, 64, 64]         --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 128, 64, 64]         131,072\n",
      "|    |    └─InstanceNorm2d: 3-4          [-1, 128, 64, 64]         --\n",
      "|    |    └─LeakyReLU: 3-5               [-1, 128, 64, 64]         --\n",
      "├─UNetDown: 1-3                          [-1, 256, 32, 32]         --\n",
      "|    └─Sequential: 2-3                   [-1, 256, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-6                  [-1, 256, 32, 32]         524,288\n",
      "|    |    └─InstanceNorm2d: 3-7          [-1, 256, 32, 32]         --\n",
      "|    |    └─LeakyReLU: 3-8               [-1, 256, 32, 32]         --\n",
      "├─UNetDown: 1-4                          [-1, 512, 16, 16]         --\n",
      "|    └─Sequential: 2-4                   [-1, 512, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 512, 16, 16]         2,097,152\n",
      "|    |    └─InstanceNorm2d: 3-10         [-1, 512, 16, 16]         --\n",
      "|    |    └─LeakyReLU: 3-11              [-1, 512, 16, 16]         --\n",
      "|    |    └─Dropout: 3-12                [-1, 512, 16, 16]         --\n",
      "├─UNetDown: 1-5                          [-1, 512, 8, 8]           --\n",
      "|    └─Sequential: 2-5                   [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 512, 8, 8]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-14         [-1, 512, 8, 8]           --\n",
      "|    |    └─LeakyReLU: 3-15              [-1, 512, 8, 8]           --\n",
      "|    |    └─Dropout: 3-16                [-1, 512, 8, 8]           --\n",
      "├─UNetDown: 1-6                          [-1, 512, 4, 4]           --\n",
      "|    └─Sequential: 2-6                   [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 512, 4, 4]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-18         [-1, 512, 4, 4]           --\n",
      "|    |    └─LeakyReLU: 3-19              [-1, 512, 4, 4]           --\n",
      "|    |    └─Dropout: 3-20                [-1, 512, 4, 4]           --\n",
      "├─UNetDown: 1-7                          [-1, 512, 2, 2]           --\n",
      "|    └─Sequential: 2-7                   [-1, 512, 2, 2]           --\n",
      "|    |    └─Conv2d: 3-21                 [-1, 512, 2, 2]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-22         [-1, 512, 2, 2]           --\n",
      "|    |    └─LeakyReLU: 3-23              [-1, 512, 2, 2]           --\n",
      "|    |    └─Dropout: 3-24                [-1, 512, 2, 2]           --\n",
      "├─UNetDown: 1-8                          [-1, 512, 1, 1]           --\n",
      "|    └─Sequential: 2-8                   [-1, 512, 1, 1]           --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 512, 1, 1]           4,194,304\n",
      "|    |    └─LeakyReLU: 3-26              [-1, 512, 1, 1]           --\n",
      "|    |    └─Dropout: 3-27                [-1, 512, 1, 1]           --\n",
      "├─UNetUp: 1-9                            [-1, 1024, 2, 2]          --\n",
      "|    └─Sequential: 2-9                   [-1, 512, 2, 2]           --\n",
      "|    |    └─ConvTranspose2d: 3-28        [-1, 512, 2, 2]           4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-29         [-1, 512, 2, 2]           --\n",
      "|    |    └─ReLU: 3-30                   [-1, 512, 2, 2]           --\n",
      "|    |    └─Dropout: 3-31                [-1, 512, 2, 2]           --\n",
      "├─UNetUp: 1-10                           [-1, 1024, 4, 4]          --\n",
      "|    └─Sequential: 2-10                  [-1, 512, 4, 4]           --\n",
      "|    |    └─ConvTranspose2d: 3-32        [-1, 512, 4, 4]           8,388,608\n",
      "|    |    └─InstanceNorm2d: 3-33         [-1, 512, 4, 4]           --\n",
      "|    |    └─ReLU: 3-34                   [-1, 512, 4, 4]           --\n",
      "|    |    └─Dropout: 3-35                [-1, 512, 4, 4]           --\n",
      "├─UNetUp: 1-11                           [-1, 1024, 8, 8]          --\n",
      "|    └─Sequential: 2-11                  [-1, 512, 8, 8]           --\n",
      "|    |    └─ConvTranspose2d: 3-36        [-1, 512, 8, 8]           8,388,608\n",
      "|    |    └─InstanceNorm2d: 3-37         [-1, 512, 8, 8]           --\n",
      "|    |    └─ReLU: 3-38                   [-1, 512, 8, 8]           --\n",
      "|    |    └─Dropout: 3-39                [-1, 512, 8, 8]           --\n",
      "├─UNetUp: 1-12                           [-1, 1024, 16, 16]        --\n",
      "|    └─Sequential: 2-12                  [-1, 512, 16, 16]         --\n",
      "|    |    └─ConvTranspose2d: 3-40        [-1, 512, 16, 16]         8,388,608\n",
      "|    |    └─InstanceNorm2d: 3-41         [-1, 512, 16, 16]         --\n",
      "|    |    └─ReLU: 3-42                   [-1, 512, 16, 16]         --\n",
      "|    |    └─Dropout: 3-43                [-1, 512, 16, 16]         --\n",
      "├─UNetUp: 1-13                           [-1, 512, 32, 32]         --\n",
      "|    └─Sequential: 2-13                  [-1, 256, 32, 32]         --\n",
      "|    |    └─ConvTranspose2d: 3-44        [-1, 256, 32, 32]         4,194,304\n",
      "|    |    └─InstanceNorm2d: 3-45         [-1, 256, 32, 32]         --\n",
      "|    |    └─ReLU: 3-46                   [-1, 256, 32, 32]         --\n",
      "├─UNetUp: 1-14                           [-1, 256, 64, 64]         --\n",
      "|    └─Sequential: 2-14                  [-1, 128, 64, 64]         --\n",
      "|    |    └─ConvTranspose2d: 3-47        [-1, 128, 64, 64]         1,048,576\n",
      "|    |    └─InstanceNorm2d: 3-48         [-1, 128, 64, 64]         --\n",
      "|    |    └─ReLU: 3-49                   [-1, 128, 64, 64]         --\n",
      "├─UNetUp: 1-15                           [-1, 128, 128, 128]       --\n",
      "|    └─Sequential: 2-15                  [-1, 64, 128, 128]        --\n",
      "|    |    └─ConvTranspose2d: 3-50        [-1, 64, 128, 128]        262,144\n",
      "|    |    └─InstanceNorm2d: 3-51         [-1, 64, 128, 128]        --\n",
      "|    |    └─ReLU: 3-52                   [-1, 64, 128, 128]        --\n",
      "├─Sequential: 1-16                       [-1, 3, 256, 256]         --\n",
      "|    └─Upsample: 2-16                    [-1, 128, 256, 256]       --\n",
      "|    └─ZeroPad2d: 2-17                   [-1, 128, 257, 257]       --\n",
      "|    └─Conv2d: 2-18                      [-1, 3, 256, 256]         6,147\n",
      "|    └─Tanh: 2-19                        [-1, 3, 256, 256]         --\n",
      "==========================================================================================\n",
      "Total params: 54,404,099\n",
      "Trainable params: 54,404,099\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 18.25\n",
      "==========================================================================================\n",
      "Input size (MB): 2.25\n",
      "Forward/backward pass size (MB): 32.16\n",
      "Params size (MB): 207.54\n",
      "Estimated Total Size (MB): 241.95\n",
      "==========================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'img_B'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3e8cdd574326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mexecuted_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[1;34m\"Failed to run torchsummary. See above stack traces for more details. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[1;34m\"Executed layers up to: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecuted_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "!pip install torch_summary\n",
    "from torchsummary import summary\n",
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "print(summary(generator, torch.zeros(3, 3, IMAGE_SIZE, IMAGE_SIZE).to(device)))\n",
    "print(summary(discriminator, torch.zeros(3, 3, IMAGE_SIZE, IMAGE_SIZE).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练时判别器和生成器的处理函数\n",
    "- 判别器中的输入为原图像（real_src），真实目标图像（real_trg)和假目标图像（fake_trg）\n",
    "    - 通过real_trg和real_src来计算error_real，这里的期望是判别器能够预测真实的图像。\n",
    "    - 通过fake_trg和real_src来计算error_fake，期望判别器能将假目标分为假图像。\n",
    "- 生成器中的输入为原图像（real_src）和假目标图像（fake_trg）\n",
    "    - 通过fake_trg和real_trg来计算loss_pixel，来计算生成图和真是图像间像素的差别。\n",
    "    - 通过预测值和real_src来计算loss_GAN，来计算GAN的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T06:22:30.830827Z",
     "start_time": "2021-04-25T06:22:30.824875Z"
    },
    "id": "69me3TlQfwFG"
   },
   "outputs": [],
   "source": [
    "def discriminator_train_step(real_src, real_trg, fake_trg):\n",
    "    #discriminator.train()\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    prediction_real = discriminator(real_trg, real_src)\n",
    "    error_real = criterion_GAN(prediction_real, torch.ones(len(real_src), 1, 16, 16).cuda())\n",
    "    error_real.backward()\n",
    "\n",
    "    prediction_fake = discriminator(fake_trg.detach(), real_src)\n",
    "    error_fake = criterion_GAN(prediction_fake, torch.zeros(len(real_src), 1, 16, 16).cuda())\n",
    "    error_fake.backward()\n",
    "\n",
    "    d_optimizer.step()\n",
    "\n",
    "    return error_real + error_fake\n",
    "\n",
    "def generator_train_step(real_src, fake_trg):\n",
    "    #discriminator.train()\n",
    "    g_optimizer.zero_grad()\n",
    "    prediction = discriminator(fake_trg, real_src)\n",
    "\n",
    "    loss_GAN = criterion_GAN(prediction, torch.ones(len(real_src), 1, 16, 16).cuda())\n",
    "    loss_pixel = criterion_pixelwise(fake_trg, real_trg)\n",
    "    loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "\n",
    "    loss_G.backward()\n",
    "    g_optimizer.step()\n",
    "    return loss_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义来获取预测样本的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = T.Normalize((-1, -1, -1), (2, 2, 2))\n",
    "def sample_prediction():\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    data = next(iter(val_dl))\n",
    "    real_src, real_trg = data\n",
    "    fake_trg = generator(real_src)\n",
    "    img_sample = torch.cat([denorm(real_src[0]), denorm(fake_trg[0]), denorm(real_trg[0])], -1)\n",
    "    img_sample = img_sample.detach().cpu().permute(1,2,0).numpy()\n",
    "    show(img_sample, title='Source::Generated::GroundTruth', sz=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关实例化，指定损失准则和优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T07:13:46.135098Z",
     "start_time": "2021-04-25T06:22:31.006806Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PHuThsmkfwFI",
    "outputId": "09173470-99da-415f-e99e-e2e66ebeb9df"
   },
   "outputs": [],
   "source": [
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "lambda_pixel = 100\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "val_dl = DataLoader(val_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "log = Report(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 4.00 GiB total capacity; 2.17 GiB already allocated; 686.76 MiB free; 2.19 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-88f0c4a5768e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfake_trg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_src\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'empty_cache'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e3c9418b51b9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mu6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mu7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[0;32m   3533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3534\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nearest\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3535\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3536\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nearest\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3537\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 4.00 GiB total capacity; 2.17 GiB already allocated; 686.76 MiB free; 2.19 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    N = len(trn_dl)\n",
    "    for bx, batch in enumerate(trn_dl):\n",
    "        real_src, real_trg = batch\n",
    "\n",
    "        fake_trg = generator(real_src)\n",
    "        \n",
    "        errD = discriminator_train_step(real_src, real_trg, fake_trg)\n",
    "        errG = generator_train_step(real_src, fake_trg)\n",
    "        log.record(pos=epoch+(1+bx)/N, errD=errD.item(), errG=errG.item(), end='\\r')\n",
    "\n",
    "    log.report_avgs(epoch+1)\n",
    "    [sample_prediction() for _ in range(2)]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
